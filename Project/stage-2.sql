-- Use the database
USE DATABASE entertainment_db;


-- To configure a secure access to cloud storage, we will be creating a storage integration used to delegate authentication responsibility for external cloud storage to a Snowflake identity and access management (IAM) entity.
CREATE STORAGE INTEGRATION IF NOT EXISTS shows_blob_integration
  TYPE = EXTERNAL_STAGE
  STORAGE_PROVIDER = 'AZURE'
  ENABLED = TRUE
  AZURE_TENANT_ID = 'xxxx-18c5-406f-8fd5-xxxxxxxx'
  STORAGE_ALLOWED_LOCATIONS = ('azure://xxxxxxx.blob.core.windows.net/doorstep');


-- Display the AZURE_CONSENT_URL. In a web browser, navigate to the URL in the AZURE_CONSENT_URL column. The page displays a Microsoft permissions request page. Follow the instructions.
DESC STORAGE INTEGRATION shows_blob_integration;


-- Create a new external STAGE in MODELS schema to use it for loading data from CSV files into Snowflake tables.
-- Azure_SAS_TOKEN specifies the SAS (shared access signature) token for connecting to Azure and accessing the private/protected container where the files containing loaded data are staged. Credentials are generated by Azure.
CREATE STAGE IF NOT EXISTS models.azure_stage
URL = 'azure://xxxxxxx.blob.core.windows.net/doorstep/'
CREDENTIALS = (AZURE_SAS_TOKEN ='xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx')
FILE_FORMAT = ( TYPE = CSV);


-- Create a snowflake task that runs on a schedule to load data from the CSV file into the Snowflake table
CREATE TASK IF NOT EXISTS models.load_data_from_file_task
WAREHOUSE = DATA_PIPELINES
SCHEDULE = '1 MINUTE'
AS
COPY INTO models.shows
FROM @azure://xxxxxxx.blob.core.windows.net/doorstep/netflix_titles.csv
FILE_FORMAT = (FORMAT_NAME = 'CSV');


-- Start the Snowflake task to begin the automated ELT process.
ALTER TASK load_data_from_file_task RESUME;